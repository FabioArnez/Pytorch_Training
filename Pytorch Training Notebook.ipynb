{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Example\n",
    "\n",
    "- Image size 28x28 pixels $\\rightarrow$ 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected MLP Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Torch Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if CPU | GPU will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU will be used for training/testing\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device == \"cuda\":\n",
    "    device_name = \"CUDA\"\n",
    "else:\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "print(\"% s will be used for training/testing\" % device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net input size\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [01:53, 117600.48it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 121461.00it/s]\u001b[A\n",
      "32768it [00:00, 123658.37it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:17, 91185.36it/s]\u001b[A\n",
      "  2%|▏         | 32768/1648877 [00:00<00:16, 97613.84it/s]\u001b[A\n",
      "  3%|▎         | 49152/1648877 [00:00<00:15, 104556.86it/s]\u001b[A\n",
      "  4%|▍         | 65536/1648877 [00:00<00:14, 110437.51it/s]\u001b[A\n",
      "  5%|▍         | 81920/1648877 [00:00<00:13, 117243.89it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:01<00:12, 122281.57it/s]\u001b[A\n",
      "  7%|▋         | 114688/1648877 [00:01<00:12, 121808.08it/s]\u001b[A\n",
      "  8%|▊         | 131072/1648877 [00:01<00:12, 121007.53it/s]\u001b[A\n",
      "  9%|▉         | 147456/1648877 [00:01<00:11, 125252.96it/s]\u001b[A\n",
      " 10%|█         | 172032/1648877 [00:01<00:11, 130689.20it/s]\u001b[A\n",
      " 12%|█▏        | 196608/1648877 [00:01<00:10, 145142.30it/s]\u001b[A\n",
      " 13%|█▎        | 212992/1648877 [00:01<00:09, 149607.05it/s]\u001b[A\n",
      " 14%|█▍        | 237568/1648877 [00:02<00:08, 162512.02it/s]\u001b[A\n",
      " 16%|█▌        | 262144/1648877 [00:02<00:14, 96120.21it/s] \u001b[A\n",
      " 17%|█▋        | 286720/1648877 [00:02<00:12, 106886.37it/s]\u001b[A\n",
      " 18%|█▊        | 303104/1648877 [00:02<00:11, 116533.95it/s]\u001b[A\n",
      " 19%|█▉        | 319488/1648877 [00:03<00:15, 87136.50it/s] \u001b[A\n",
      " 21%|██        | 344064/1648877 [00:03<00:14, 88221.49it/s]\u001b[A\n",
      " 22%|██▏       | 360448/1648877 [00:03<00:15, 84905.16it/s]\u001b[A\n",
      " 23%|██▎       | 376832/1648877 [00:03<00:16, 79159.02it/s]\u001b[A\n",
      " 24%|██▍       | 393216/1648877 [00:03<00:15, 83585.18it/s]\u001b[A\n",
      " 25%|██▍       | 409600/1648877 [00:04<00:13, 91277.08it/s]\u001b[A\n",
      " 26%|██▌       | 425984/1648877 [00:04<00:14, 85002.31it/s]\u001b[A\n",
      " 27%|██▋       | 442368/1648877 [00:04<00:14, 80861.96it/s]\u001b[A\n",
      " 28%|██▊       | 458752/1648877 [00:04<00:15, 78807.36it/s]\u001b[A\n",
      " 29%|██▉       | 475136/1648877 [00:04<00:13, 87338.20it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:05<00:12, 90963.38it/s]\u001b[A\n",
      " 31%|███       | 507904/1648877 [00:05<00:11, 96294.92it/s]\u001b[A\n",
      " 32%|███▏      | 524288/1648877 [00:05<00:11, 101575.28it/s]\u001b[A\n",
      " 33%|███▎      | 540672/1648877 [00:05<00:10, 103883.98it/s]\u001b[A\n",
      " 34%|███▍      | 557056/1648877 [00:05<00:09, 110633.19it/s]\u001b[A\n",
      " 35%|███▍      | 573440/1648877 [00:05<00:09, 118794.51it/s]\u001b[A\n",
      " 36%|███▌      | 589824/1648877 [00:05<00:08, 120681.32it/s]\u001b[A\n",
      " 37%|███▋      | 606208/1648877 [00:06<00:10, 99951.13it/s] \u001b[A\n",
      " 38%|███▊      | 622592/1648877 [00:06<00:10, 97276.05it/s]\u001b[A\n",
      " 39%|███▉      | 638976/1648877 [00:06<00:09, 106235.43it/s]\u001b[A\n",
      " 40%|███▉      | 655360/1648877 [00:06<00:11, 87195.94it/s] \u001b[A\n",
      " 41%|████      | 671744/1648877 [00:06<00:12, 80137.03it/s]\u001b[A\n",
      " 42%|████▏     | 688128/1648877 [00:07<00:12, 79462.49it/s]\u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:07<00:10, 86601.10it/s]\u001b[A\n",
      " 44%|████▎     | 720896/1648877 [00:07<00:10, 89329.89it/s]\u001b[A\n",
      " 45%|████▍     | 737280/1648877 [00:07<00:10, 88366.21it/s]\u001b[A\n",
      " 46%|████▌     | 753664/1648877 [00:07<00:09, 92354.76it/s]\u001b[A\n",
      " 47%|████▋     | 770048/1648877 [00:07<00:09, 92698.81it/s]\u001b[A\n",
      " 48%|████▊     | 786432/1648877 [00:08<00:08, 101356.41it/s]\u001b[A\n",
      " 49%|████▊     | 802816/1648877 [00:08<00:07, 109977.51it/s]\u001b[A\n",
      " 50%|████▉     | 819200/1648877 [00:08<00:06, 118613.67it/s]\u001b[A\n",
      " 51%|█████     | 835584/1648877 [00:08<00:09, 88045.26it/s] \u001b[A\n",
      " 52%|█████▏    | 860160/1648877 [00:08<00:08, 96413.75it/s]\u001b[A\n",
      " 53%|█████▎    | 876544/1648877 [00:08<00:07, 101405.05it/s]\u001b[A\n",
      " 54%|█████▍    | 892928/1648877 [00:09<00:09, 76266.19it/s] \u001b[A\n",
      " 56%|█████▌    | 917504/1648877 [00:09<00:07, 91834.15it/s]\u001b[A\n",
      " 57%|█████▋    | 933888/1648877 [00:09<00:08, 88306.53it/s]\u001b[A\n",
      " 58%|█████▊    | 950272/1648877 [00:09<00:07, 92462.74it/s]\u001b[A\n",
      " 59%|█████▊    | 966656/1648877 [00:10<00:07, 93510.93it/s]\u001b[A\n",
      " 60%|█████▉    | 983040/1648877 [00:10<00:06, 97979.05it/s]\u001b[A\n",
      " 61%|██████    | 999424/1648877 [00:10<00:08, 76593.36it/s]\u001b[A\n",
      " 62%|██████▏   | 1015808/1648877 [00:10<00:07, 80890.96it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:10<00:08, 72084.23it/s]\u001b[A\n",
      " 63%|██████▎   | 1040384/1648877 [00:11<00:23, 26345.27it/s]\u001b[A\n",
      " 64%|██████▎   | 1048576/1648877 [00:11<00:19, 30519.50it/s]\u001b[A\n",
      " 65%|██████▍   | 1064960/1648877 [00:12<00:15, 38010.16it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:12<00:12, 46306.73it/s]\u001b[A\n",
      " 66%|██████▌   | 1089536/1648877 [00:12<00:12, 45759.22it/s]\u001b[A\n",
      " 67%|██████▋   | 1105920/1648877 [00:12<00:09, 56266.77it/s]\u001b[A\n",
      " 68%|██████▊   | 1122304/1648877 [00:12<00:08, 63737.02it/s]\u001b[A\n",
      " 69%|██████▉   | 1138688/1648877 [00:12<00:07, 69254.24it/s]\u001b[A\n",
      " 70%|███████   | 1155072/1648877 [00:13<00:06, 75588.74it/s]\u001b[A\n",
      " 71%|███████   | 1171456/1648877 [00:13<00:05, 80037.65it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:13<00:05, 83010.26it/s]\u001b[A\n",
      " 73%|███████▎  | 1204224/1648877 [00:13<00:04, 89617.39it/s]\u001b[A\n",
      " 74%|███████▍  | 1220608/1648877 [00:13<00:04, 89030.22it/s]\u001b[A\n",
      " 75%|███████▌  | 1236992/1648877 [00:13<00:04, 90873.62it/s]\u001b[A\n",
      " 76%|███████▌  | 1253376/1648877 [00:14<00:04, 91297.07it/s]\u001b[A\n",
      " 78%|███████▊  | 1277952/1648877 [00:14<00:03, 101590.40it/s]\u001b[A\n",
      " 78%|███████▊  | 1294336/1648877 [00:14<00:03, 98441.11it/s] \u001b[A\n",
      " 79%|███████▉  | 1310720/1648877 [00:14<00:03, 106525.31it/s]\u001b[A\n",
      " 81%|████████  | 1335296/1648877 [00:14<00:02, 120853.88it/s]\u001b[A\n",
      " 82%|████████▏ | 1359872/1648877 [00:14<00:02, 128924.15it/s]\u001b[A\n",
      " 84%|████████▍ | 1384448/1648877 [00:15<00:01, 137743.26it/s]\u001b[A\n",
      " 85%|████████▌ | 1409024/1648877 [00:15<00:01, 149958.98it/s]\u001b[A\n",
      "9920512it [02:10, 117600.48it/s] [00:15<00:01, 160050.65it/s]\u001b[A\n",
      " 88%|████████▊ | 1458176/1648877 [00:15<00:01, 171100.87it/s]\u001b[A\n",
      " 90%|████████▉ | 1482752/1648877 [00:15<00:00, 180098.36it/s]\u001b[A\n",
      " 91%|█████████▏| 1507328/1648877 [00:15<00:01, 120619.64it/s]\u001b[A\n",
      " 92%|█████████▏| 1523712/1648877 [00:16<00:01, 103642.41it/s]\u001b[A\n",
      " 93%|█████████▎| 1540096/1648877 [00:16<00:00, 109645.89it/s]\u001b[A\n",
      " 94%|█████████▍| 1556480/1648877 [00:16<00:00, 101425.65it/s]\u001b[A\n",
      " 95%|█████████▌| 1572864/1648877 [00:16<00:00, 112115.25it/s]\u001b[A\n",
      " 96%|█████████▋| 1589248/1648877 [00:16<00:00, 95606.32it/s] \u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:17<00:00, 89364.80it/s]\u001b[A\n",
      " 98%|█████████▊| 1622016/1648877 [00:17<00:00, 87184.95it/s]\u001b[A\n",
      " 99%|█████████▉| 1638400/1648877 [00:17<00:00, 84802.61it/s]\u001b[A\n",
      "1654784it [00:17, 94928.22it/s]                             \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 31450.96it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='../data',\n",
    "                                           train=True,\n",
    "                                           transform= transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../data',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the nueral network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcnNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNet_model = FcnNeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(neuralNet_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step[100/600], Loss:0.0025\n",
      "Epoch [1/10], Step[200/600], Loss:0.0047\n",
      "Epoch [1/10], Step[300/600], Loss:0.0019\n",
      "Epoch [1/10], Step[400/600], Loss:0.0049\n",
      "Epoch [1/10], Step[500/600], Loss:0.0029\n",
      "Epoch [1/10], Step[600/600], Loss:0.0027\n",
      "Epoch [2/10], Step[100/600], Loss:0.0036\n",
      "Epoch [2/10], Step[200/600], Loss:0.0018\n",
      "Epoch [2/10], Step[300/600], Loss:0.0018\n",
      "Epoch [2/10], Step[400/600], Loss:0.0111\n",
      "Epoch [2/10], Step[500/600], Loss:0.0015\n",
      "Epoch [2/10], Step[600/600], Loss:0.0111\n",
      "Epoch [3/10], Step[100/600], Loss:0.0112\n",
      "Epoch [3/10], Step[200/600], Loss:0.0020\n",
      "Epoch [3/10], Step[300/600], Loss:0.0044\n",
      "Epoch [3/10], Step[400/600], Loss:0.0028\n",
      "Epoch [3/10], Step[500/600], Loss:0.0375\n",
      "Epoch [3/10], Step[600/600], Loss:0.0010\n",
      "Epoch [4/10], Step[100/600], Loss:0.0075\n",
      "Epoch [4/10], Step[200/600], Loss:0.0013\n",
      "Epoch [4/10], Step[300/600], Loss:0.0019\n",
      "Epoch [4/10], Step[400/600], Loss:0.0003\n",
      "Epoch [4/10], Step[500/600], Loss:0.0030\n",
      "Epoch [4/10], Step[600/600], Loss:0.0036\n",
      "Epoch [5/10], Step[100/600], Loss:0.0022\n",
      "Epoch [5/10], Step[200/600], Loss:0.0028\n",
      "Epoch [5/10], Step[300/600], Loss:0.0120\n",
      "Epoch [5/10], Step[400/600], Loss:0.0018\n",
      "Epoch [5/10], Step[500/600], Loss:0.0041\n",
      "Epoch [5/10], Step[600/600], Loss:0.0013\n",
      "Epoch [6/10], Step[100/600], Loss:0.0004\n",
      "Epoch [6/10], Step[200/600], Loss:0.0032\n",
      "Epoch [6/10], Step[300/600], Loss:0.0010\n",
      "Epoch [6/10], Step[400/600], Loss:0.0003\n",
      "Epoch [6/10], Step[500/600], Loss:0.0081\n",
      "Epoch [6/10], Step[600/600], Loss:0.0042\n",
      "Epoch [7/10], Step[100/600], Loss:0.0004\n",
      "Epoch [7/10], Step[200/600], Loss:0.0012\n",
      "Epoch [7/10], Step[300/600], Loss:0.0004\n",
      "Epoch [7/10], Step[400/600], Loss:0.0003\n",
      "Epoch [7/10], Step[500/600], Loss:0.0014\n",
      "Epoch [7/10], Step[600/600], Loss:0.0003\n",
      "Epoch [8/10], Step[100/600], Loss:0.0010\n",
      "Epoch [8/10], Step[200/600], Loss:0.0054\n",
      "Epoch [8/10], Step[300/600], Loss:0.0015\n",
      "Epoch [8/10], Step[400/600], Loss:0.0128\n",
      "Epoch [8/10], Step[500/600], Loss:0.0013\n",
      "Epoch [8/10], Step[600/600], Loss:0.0007\n",
      "Epoch [9/10], Step[100/600], Loss:0.0004\n",
      "Epoch [9/10], Step[200/600], Loss:0.0009\n",
      "Epoch [9/10], Step[300/600], Loss:0.0246\n",
      "Epoch [9/10], Step[400/600], Loss:0.0006\n",
      "Epoch [9/10], Step[500/600], Loss:0.0012\n",
      "Epoch [9/10], Step[600/600], Loss:0.0002\n",
      "Epoch [10/10], Step[100/600], Loss:0.0002\n",
      "Epoch [10/10], Step[200/600], Loss:0.0001\n",
      "Epoch [10/10], Step[300/600], Loss:0.0007\n",
      "Epoch [10/10], Step[400/600], Loss:0.0012\n",
      "Epoch [10/10], Step[500/600], Loss:0.0002\n",
      "Epoch [10/10], Step[600/600], Loss:0.0001\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images =  images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = neuralNet_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step[{}/{}], Loss:{:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.17 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = neuralNet_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.FcnNeuralNet'>\n"
     ]
    }
   ],
   "source": [
    "print(FcnNeuralNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected MLP with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net input size\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                   download=False, transform=transform)\n",
    "test_data = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                  download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a batch of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# obtain one batch of training images\n",
    "batch_iter = iter(train_loader)\n",
    "images_batch, labels_batch = batch_iter.next()\n",
    "\n",
    "image = images_batch[0]\n",
    "\n",
    "img = np.array(image, dtype='float')\n",
    "img = img.reshape((28, 28))\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "batch_iter = iter(train_loader)\n",
    "images_batch, labels_batch = batch_iter.next()\n",
    "\n",
    "plt.figure(figsize=(25, 4))\n",
    "for idx, image in enumerate(images_batch):\n",
    "    img = np.array(image, dtype='float')\n",
    "    img = img.reshape((28, 28))\n",
    "    plt.subplot(2, 10, (idx + 1))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FcnNeuralNetDropOut(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout_02): Dropout(p=0.2, inplace=False)\n",
      "  (dropout_04): Dropout(p=0.4, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "class FcnNeuralNetDropOut(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 512\n",
    "        hidden_2 = 512\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(28 * 28, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(hidden_2, 10)\n",
    "        # dropout prevents overfitting of data\n",
    "        # dropout layer (p=0.2)\n",
    "        self.dropout_02 = nn.Dropout(0.2)\n",
    "        # dropout layer (p=0.1)        \n",
    "        self.dropout_04 = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout_04(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout_02(x)\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = FcnNeuralNetDropOut()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Specify Loss Function and Optimizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train the Network__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.068186 \tValidation Loss: 0.088730\n",
      "Validation loss decreased (inf --> 0.088730).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.065492 \tValidation Loss: 0.088231\n",
      "Validation loss decreased (0.088730 --> 0.088231).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.068001 \tValidation Loss: 0.100062\n",
      "Epoch: 4 \tTraining Loss: 0.066416 \tValidation Loss: 0.094076\n",
      "Epoch: 5 \tTraining Loss: 0.059596 \tValidation Loss: 0.104634\n",
      "Epoch: 6 \tTraining Loss: 0.061655 \tValidation Loss: 0.084733\n",
      "Validation loss decreased (0.088231 --> 0.084733).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.064669 \tValidation Loss: 0.087438\n",
      "Epoch: 8 \tTraining Loss: 0.054673 \tValidation Loss: 0.093786\n",
      "Epoch: 9 \tTraining Loss: 0.056852 \tValidation Loss: 0.107081\n",
      "Epoch: 10 \tTraining Loss: 0.059394 \tValidation Loss: 0.105237\n",
      "Epoch: 11 \tTraining Loss: 0.054766 \tValidation Loss: 0.109171\n",
      "Epoch: 12 \tTraining Loss: 0.058295 \tValidation Loss: 0.109712\n",
      "Epoch: 13 \tTraining Loss: 0.055396 \tValidation Loss: 0.106470\n",
      "Epoch: 14 \tTraining Loss: 0.054762 \tValidation Loss: 0.103383\n",
      "Epoch: 15 \tTraining Loss: 0.054683 \tValidation Loss: 0.106597\n",
      "Epoch: 16 \tTraining Loss: 0.051931 \tValidation Loss: 0.119941\n",
      "Epoch: 17 \tTraining Loss: 0.052005 \tValidation Loss: 0.122916\n",
      "Epoch: 18 \tTraining Loss: 0.050420 \tValidation Loss: 0.109381\n",
      "Epoch: 19 \tTraining Loss: 0.052001 \tValidation Loss: 0.129538\n",
      "Epoch: 20 \tTraining Loss: 0.047789 \tValidation Loss: 0.111548\n",
      "Epoch: 21 \tTraining Loss: 0.051997 \tValidation Loss: 0.119359\n",
      "Epoch: 22 \tTraining Loss: 0.052993 \tValidation Loss: 0.127088\n",
      "Epoch: 23 \tTraining Loss: 0.051769 \tValidation Loss: 0.112313\n",
      "Epoch: 24 \tTraining Loss: 0.055838 \tValidation Loss: 0.120123\n",
      "Epoch: 25 \tTraining Loss: 0.055323 \tValidation Loss: 0.117556\n",
      "Epoch: 26 \tTraining Loss: 0.054809 \tValidation Loss: 0.121423\n",
      "Epoch: 27 \tTraining Loss: 0.049908 \tValidation Loss: 0.134193\n",
      "Epoch: 28 \tTraining Loss: 0.050503 \tValidation Loss: 0.137952\n",
      "Epoch: 29 \tTraining Loss: 0.045853 \tValidation Loss: 0.141098\n",
      "Epoch: 30 \tTraining Loss: 0.052444 \tValidation Loss: 0.148425\n",
      "Epoch: 31 \tTraining Loss: 0.047681 \tValidation Loss: 0.127192\n",
      "Epoch: 32 \tTraining Loss: 0.050529 \tValidation Loss: 0.123909\n",
      "Epoch: 33 \tTraining Loss: 0.049338 \tValidation Loss: 0.146092\n",
      "Epoch: 34 \tTraining Loss: 0.052991 \tValidation Loss: 0.157256\n",
      "Epoch: 35 \tTraining Loss: 0.049269 \tValidation Loss: 0.139673\n",
      "Epoch: 36 \tTraining Loss: 0.044654 \tValidation Loss: 0.142369\n",
      "Epoch: 37 \tTraining Loss: 0.052696 \tValidation Loss: 0.144235\n",
      "Epoch: 38 \tTraining Loss: 0.053152 \tValidation Loss: 0.121661\n",
      "Epoch: 39 \tTraining Loss: 0.043954 \tValidation Loss: 0.163546\n",
      "Epoch: 40 \tTraining Loss: 0.050323 \tValidation Loss: 0.154691\n",
      "Epoch: 41 \tTraining Loss: 0.047152 \tValidation Loss: 0.152447\n",
      "Epoch: 42 \tTraining Loss: 0.048427 \tValidation Loss: 0.158086\n",
      "Epoch: 43 \tTraining Loss: 0.052046 \tValidation Loss: 0.153681\n",
      "Epoch: 44 \tTraining Loss: 0.049024 \tValidation Loss: 0.163421\n",
      "Epoch: 45 \tTraining Loss: 0.051213 \tValidation Loss: 0.171392\n",
      "Epoch: 46 \tTraining Loss: 0.051690 \tValidation Loss: 0.172513\n",
      "Epoch: 47 \tTraining Loss: 0.048510 \tValidation Loss: 0.175881\n",
      "Epoch: 48 \tTraining Loss: 0.054899 \tValidation Loss: 0.159657\n",
      "Epoch: 49 \tTraining Loss: 0.046969 \tValidation Loss: 0.156152\n",
      "Epoch: 50 \tTraining Loss: 0.050192 \tValidation Loss: 0.183178\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 50\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, target in valid_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test the Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dropout(m):\n",
    "    if type(m) == nn.Dropout:\n",
    "        m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FcnNeuralNetDropOut(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout_02): Dropout(p=0.2, inplace=False)\n",
       "  (dropout_04): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "# prep model for evaluation\n",
    "model.eval()\n",
    "# Apply dropout on testing\n",
    "model.apply(apply_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.133751\n",
      "\n",
      "Test Accuracy of     0: 98% (965/980)\n",
      "Test Accuracy of     1: 98% (1122/1135)\n",
      "Test Accuracy of     2: 96% (1000/1032)\n",
      "Test Accuracy of     3: 96% (976/1010)\n",
      "Test Accuracy of     4: 97% (954/982)\n",
      "Test Accuracy of     5: 97% (868/892)\n",
      "Test Accuracy of     6: 97% (937/958)\n",
      "Test Accuracy of     7: 97% (998/1028)\n",
      "Test Accuracy of     8: 93% (908/974)\n",
      "Test Accuracy of     9: 95% (964/1009)\n",
      "\n",
      "Test Accuracy (Overall): 96% (9692/10000)\n"
     ]
    }
   ],
   "source": [
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
