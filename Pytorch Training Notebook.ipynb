{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Pytorch Training Notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioArnez/Pytorch_Training/blob/master/Pytorch%20Training%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n_I4QKbSdwR",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Training Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP6wxI_SSdwT",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Example\n",
        "\n",
        "- Image size 28x28 pixels $\\rightarrow$ 784"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH5yNIrQSdwT",
        "colab_type": "text"
      },
      "source": [
        "### Fully Connected MLP Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU0Us_7HSdwU",
        "colab_type": "text"
      },
      "source": [
        "Import Torch Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYxrRJl1SdwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbQ7gxH-SdwX",
        "colab_type": "text"
      },
      "source": [
        "Check if CPU | GPU will be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz1QBgSlSdwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19f5a59c-890a-499c-9cd5-9020edd672b8"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if device == \"cuda\":\n",
        "    device_name = \"CUDA\"\n",
        "else:\n",
        "    device_name = \"CPU\"\n",
        "\n",
        "print(\"% s will be used for training/testing\" % device_name)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU will be used for training/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yKV3eAaSdwa",
        "colab_type": "text"
      },
      "source": [
        "Define network Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARCuqbjXSdwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neural net input size\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR9EyEheSdwd",
        "colab_type": "text"
      },
      "source": [
        "Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZR7iXJmSdwd",
        "colab_type": "code",
        "colab": {},
        "outputId": "b8e8c3fd-eb3c-431b-e07a-341b67e827c6"
      },
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='../data',\n",
        "                                           train=True,\n",
        "                                           transform= transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [01:53, 117600.48it/s]                             "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
            " 57%|█████▋    | 16384/28881 [00:00<00:00, 121461.00it/s]\u001b[A\n",
            "32768it [00:00, 123658.37it/s]                           \u001b[A\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 16384/1648877 [00:00<00:17, 91185.36it/s]\u001b[A\n",
            "  2%|▏         | 32768/1648877 [00:00<00:16, 97613.84it/s]\u001b[A\n",
            "  3%|▎         | 49152/1648877 [00:00<00:15, 104556.86it/s]\u001b[A\n",
            "  4%|▍         | 65536/1648877 [00:00<00:14, 110437.51it/s]\u001b[A\n",
            "  5%|▍         | 81920/1648877 [00:00<00:13, 117243.89it/s]\u001b[A\n",
            "  6%|▌         | 98304/1648877 [00:01<00:12, 122281.57it/s]\u001b[A\n",
            "  7%|▋         | 114688/1648877 [00:01<00:12, 121808.08it/s]\u001b[A\n",
            "  8%|▊         | 131072/1648877 [00:01<00:12, 121007.53it/s]\u001b[A\n",
            "  9%|▉         | 147456/1648877 [00:01<00:11, 125252.96it/s]\u001b[A\n",
            " 10%|█         | 172032/1648877 [00:01<00:11, 130689.20it/s]\u001b[A\n",
            " 12%|█▏        | 196608/1648877 [00:01<00:10, 145142.30it/s]\u001b[A\n",
            " 13%|█▎        | 212992/1648877 [00:01<00:09, 149607.05it/s]\u001b[A\n",
            " 14%|█▍        | 237568/1648877 [00:02<00:08, 162512.02it/s]\u001b[A\n",
            " 16%|█▌        | 262144/1648877 [00:02<00:14, 96120.21it/s] \u001b[A\n",
            " 17%|█▋        | 286720/1648877 [00:02<00:12, 106886.37it/s]\u001b[A\n",
            " 18%|█▊        | 303104/1648877 [00:02<00:11, 116533.95it/s]\u001b[A\n",
            " 19%|█▉        | 319488/1648877 [00:03<00:15, 87136.50it/s] \u001b[A\n",
            " 21%|██        | 344064/1648877 [00:03<00:14, 88221.49it/s]\u001b[A\n",
            " 22%|██▏       | 360448/1648877 [00:03<00:15, 84905.16it/s]\u001b[A\n",
            " 23%|██▎       | 376832/1648877 [00:03<00:16, 79159.02it/s]\u001b[A\n",
            " 24%|██▍       | 393216/1648877 [00:03<00:15, 83585.18it/s]\u001b[A\n",
            " 25%|██▍       | 409600/1648877 [00:04<00:13, 91277.08it/s]\u001b[A\n",
            " 26%|██▌       | 425984/1648877 [00:04<00:14, 85002.31it/s]\u001b[A\n",
            " 27%|██▋       | 442368/1648877 [00:04<00:14, 80861.96it/s]\u001b[A\n",
            " 28%|██▊       | 458752/1648877 [00:04<00:15, 78807.36it/s]\u001b[A\n",
            " 29%|██▉       | 475136/1648877 [00:04<00:13, 87338.20it/s]\u001b[A\n",
            " 30%|██▉       | 491520/1648877 [00:05<00:12, 90963.38it/s]\u001b[A\n",
            " 31%|███       | 507904/1648877 [00:05<00:11, 96294.92it/s]\u001b[A\n",
            " 32%|███▏      | 524288/1648877 [00:05<00:11, 101575.28it/s]\u001b[A\n",
            " 33%|███▎      | 540672/1648877 [00:05<00:10, 103883.98it/s]\u001b[A\n",
            " 34%|███▍      | 557056/1648877 [00:05<00:09, 110633.19it/s]\u001b[A\n",
            " 35%|███▍      | 573440/1648877 [00:05<00:09, 118794.51it/s]\u001b[A\n",
            " 36%|███▌      | 589824/1648877 [00:05<00:08, 120681.32it/s]\u001b[A\n",
            " 37%|███▋      | 606208/1648877 [00:06<00:10, 99951.13it/s] \u001b[A\n",
            " 38%|███▊      | 622592/1648877 [00:06<00:10, 97276.05it/s]\u001b[A\n",
            " 39%|███▉      | 638976/1648877 [00:06<00:09, 106235.43it/s]\u001b[A\n",
            " 40%|███▉      | 655360/1648877 [00:06<00:11, 87195.94it/s] \u001b[A\n",
            " 41%|████      | 671744/1648877 [00:06<00:12, 80137.03it/s]\u001b[A\n",
            " 42%|████▏     | 688128/1648877 [00:07<00:12, 79462.49it/s]\u001b[A\n",
            " 43%|████▎     | 704512/1648877 [00:07<00:10, 86601.10it/s]\u001b[A\n",
            " 44%|████▎     | 720896/1648877 [00:07<00:10, 89329.89it/s]\u001b[A\n",
            " 45%|████▍     | 737280/1648877 [00:07<00:10, 88366.21it/s]\u001b[A\n",
            " 46%|████▌     | 753664/1648877 [00:07<00:09, 92354.76it/s]\u001b[A\n",
            " 47%|████▋     | 770048/1648877 [00:07<00:09, 92698.81it/s]\u001b[A\n",
            " 48%|████▊     | 786432/1648877 [00:08<00:08, 101356.41it/s]\u001b[A\n",
            " 49%|████▊     | 802816/1648877 [00:08<00:07, 109977.51it/s]\u001b[A\n",
            " 50%|████▉     | 819200/1648877 [00:08<00:06, 118613.67it/s]\u001b[A\n",
            " 51%|█████     | 835584/1648877 [00:08<00:09, 88045.26it/s] \u001b[A\n",
            " 52%|█████▏    | 860160/1648877 [00:08<00:08, 96413.75it/s]\u001b[A\n",
            " 53%|█████▎    | 876544/1648877 [00:08<00:07, 101405.05it/s]\u001b[A\n",
            " 54%|█████▍    | 892928/1648877 [00:09<00:09, 76266.19it/s] \u001b[A\n",
            " 56%|█████▌    | 917504/1648877 [00:09<00:07, 91834.15it/s]\u001b[A\n",
            " 57%|█████▋    | 933888/1648877 [00:09<00:08, 88306.53it/s]\u001b[A\n",
            " 58%|█████▊    | 950272/1648877 [00:09<00:07, 92462.74it/s]\u001b[A\n",
            " 59%|█████▊    | 966656/1648877 [00:10<00:07, 93510.93it/s]\u001b[A\n",
            " 60%|█████▉    | 983040/1648877 [00:10<00:06, 97979.05it/s]\u001b[A\n",
            " 61%|██████    | 999424/1648877 [00:10<00:08, 76593.36it/s]\u001b[A\n",
            " 62%|██████▏   | 1015808/1648877 [00:10<00:07, 80890.96it/s]\u001b[A\n",
            " 63%|██████▎   | 1032192/1648877 [00:10<00:08, 72084.23it/s]\u001b[A\n",
            " 63%|██████▎   | 1040384/1648877 [00:11<00:23, 26345.27it/s]\u001b[A\n",
            " 64%|██████▎   | 1048576/1648877 [00:11<00:19, 30519.50it/s]\u001b[A\n",
            " 65%|██████▍   | 1064960/1648877 [00:12<00:15, 38010.16it/s]\u001b[A\n",
            " 66%|██████▌   | 1081344/1648877 [00:12<00:12, 46306.73it/s]\u001b[A\n",
            " 66%|██████▌   | 1089536/1648877 [00:12<00:12, 45759.22it/s]\u001b[A\n",
            " 67%|██████▋   | 1105920/1648877 [00:12<00:09, 56266.77it/s]\u001b[A\n",
            " 68%|██████▊   | 1122304/1648877 [00:12<00:08, 63737.02it/s]\u001b[A\n",
            " 69%|██████▉   | 1138688/1648877 [00:12<00:07, 69254.24it/s]\u001b[A\n",
            " 70%|███████   | 1155072/1648877 [00:13<00:06, 75588.74it/s]\u001b[A\n",
            " 71%|███████   | 1171456/1648877 [00:13<00:05, 80037.65it/s]\u001b[A\n",
            " 72%|███████▏  | 1187840/1648877 [00:13<00:05, 83010.26it/s]\u001b[A\n",
            " 73%|███████▎  | 1204224/1648877 [00:13<00:04, 89617.39it/s]\u001b[A\n",
            " 74%|███████▍  | 1220608/1648877 [00:13<00:04, 89030.22it/s]\u001b[A\n",
            " 75%|███████▌  | 1236992/1648877 [00:13<00:04, 90873.62it/s]\u001b[A\n",
            " 76%|███████▌  | 1253376/1648877 [00:14<00:04, 91297.07it/s]\u001b[A\n",
            " 78%|███████▊  | 1277952/1648877 [00:14<00:03, 101590.40it/s]\u001b[A\n",
            " 78%|███████▊  | 1294336/1648877 [00:14<00:03, 98441.11it/s] \u001b[A\n",
            " 79%|███████▉  | 1310720/1648877 [00:14<00:03, 106525.31it/s]\u001b[A\n",
            " 81%|████████  | 1335296/1648877 [00:14<00:02, 120853.88it/s]\u001b[A\n",
            " 82%|████████▏ | 1359872/1648877 [00:14<00:02, 128924.15it/s]\u001b[A\n",
            " 84%|████████▍ | 1384448/1648877 [00:15<00:01, 137743.26it/s]\u001b[A\n",
            " 85%|████████▌ | 1409024/1648877 [00:15<00:01, 149958.98it/s]\u001b[A\n",
            "9920512it [02:10, 117600.48it/s] [00:15<00:01, 160050.65it/s]\u001b[A\n",
            " 88%|████████▊ | 1458176/1648877 [00:15<00:01, 171100.87it/s]\u001b[A\n",
            " 90%|████████▉ | 1482752/1648877 [00:15<00:00, 180098.36it/s]\u001b[A\n",
            " 91%|█████████▏| 1507328/1648877 [00:15<00:01, 120619.64it/s]\u001b[A\n",
            " 92%|█████████▏| 1523712/1648877 [00:16<00:01, 103642.41it/s]\u001b[A\n",
            " 93%|█████████▎| 1540096/1648877 [00:16<00:00, 109645.89it/s]\u001b[A\n",
            " 94%|█████████▍| 1556480/1648877 [00:16<00:00, 101425.65it/s]\u001b[A\n",
            " 95%|█████████▌| 1572864/1648877 [00:16<00:00, 112115.25it/s]\u001b[A\n",
            " 96%|█████████▋| 1589248/1648877 [00:16<00:00, 95606.32it/s] \u001b[A\n",
            " 97%|█████████▋| 1605632/1648877 [00:17<00:00, 89364.80it/s]\u001b[A\n",
            " 98%|█████████▊| 1622016/1648877 [00:17<00:00, 87184.95it/s]\u001b[A\n",
            " 99%|█████████▉| 1638400/1648877 [00:17<00:00, 84802.61it/s]\u001b[A\n",
            "1654784it [00:17, 94928.22it/s]                             \u001b[A\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "8192it [00:00, 31450.96it/s]            \u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFTiFRYNSdwf",
        "colab_type": "text"
      },
      "source": [
        "Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjSFMUYhSdwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItjB6HpZSdwh",
        "colab_type": "text"
      },
      "source": [
        "Build the nueral network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHIgWbIiSdwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FcnNeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9hJh4bRSdwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neuralNet_model = FcnNeuralNet(input_size, hidden_size, num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83T315HDSdwl",
        "colab_type": "text"
      },
      "source": [
        "Loss Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8iZKFWBSdwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(neuralNet_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL1HISSTSdwn",
        "colab_type": "text"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwNfvWkrSdwo",
        "colab_type": "code",
        "colab": {},
        "outputId": "277d07f9-65c1-4f6c-d7c7-829f843ac382"
      },
      "source": [
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images =  images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = neuralNet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step[{}/{}], Loss:{:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step[100/600], Loss:0.0025\n",
            "Epoch [1/10], Step[200/600], Loss:0.0047\n",
            "Epoch [1/10], Step[300/600], Loss:0.0019\n",
            "Epoch [1/10], Step[400/600], Loss:0.0049\n",
            "Epoch [1/10], Step[500/600], Loss:0.0029\n",
            "Epoch [1/10], Step[600/600], Loss:0.0027\n",
            "Epoch [2/10], Step[100/600], Loss:0.0036\n",
            "Epoch [2/10], Step[200/600], Loss:0.0018\n",
            "Epoch [2/10], Step[300/600], Loss:0.0018\n",
            "Epoch [2/10], Step[400/600], Loss:0.0111\n",
            "Epoch [2/10], Step[500/600], Loss:0.0015\n",
            "Epoch [2/10], Step[600/600], Loss:0.0111\n",
            "Epoch [3/10], Step[100/600], Loss:0.0112\n",
            "Epoch [3/10], Step[200/600], Loss:0.0020\n",
            "Epoch [3/10], Step[300/600], Loss:0.0044\n",
            "Epoch [3/10], Step[400/600], Loss:0.0028\n",
            "Epoch [3/10], Step[500/600], Loss:0.0375\n",
            "Epoch [3/10], Step[600/600], Loss:0.0010\n",
            "Epoch [4/10], Step[100/600], Loss:0.0075\n",
            "Epoch [4/10], Step[200/600], Loss:0.0013\n",
            "Epoch [4/10], Step[300/600], Loss:0.0019\n",
            "Epoch [4/10], Step[400/600], Loss:0.0003\n",
            "Epoch [4/10], Step[500/600], Loss:0.0030\n",
            "Epoch [4/10], Step[600/600], Loss:0.0036\n",
            "Epoch [5/10], Step[100/600], Loss:0.0022\n",
            "Epoch [5/10], Step[200/600], Loss:0.0028\n",
            "Epoch [5/10], Step[300/600], Loss:0.0120\n",
            "Epoch [5/10], Step[400/600], Loss:0.0018\n",
            "Epoch [5/10], Step[500/600], Loss:0.0041\n",
            "Epoch [5/10], Step[600/600], Loss:0.0013\n",
            "Epoch [6/10], Step[100/600], Loss:0.0004\n",
            "Epoch [6/10], Step[200/600], Loss:0.0032\n",
            "Epoch [6/10], Step[300/600], Loss:0.0010\n",
            "Epoch [6/10], Step[400/600], Loss:0.0003\n",
            "Epoch [6/10], Step[500/600], Loss:0.0081\n",
            "Epoch [6/10], Step[600/600], Loss:0.0042\n",
            "Epoch [7/10], Step[100/600], Loss:0.0004\n",
            "Epoch [7/10], Step[200/600], Loss:0.0012\n",
            "Epoch [7/10], Step[300/600], Loss:0.0004\n",
            "Epoch [7/10], Step[400/600], Loss:0.0003\n",
            "Epoch [7/10], Step[500/600], Loss:0.0014\n",
            "Epoch [7/10], Step[600/600], Loss:0.0003\n",
            "Epoch [8/10], Step[100/600], Loss:0.0010\n",
            "Epoch [8/10], Step[200/600], Loss:0.0054\n",
            "Epoch [8/10], Step[300/600], Loss:0.0015\n",
            "Epoch [8/10], Step[400/600], Loss:0.0128\n",
            "Epoch [8/10], Step[500/600], Loss:0.0013\n",
            "Epoch [8/10], Step[600/600], Loss:0.0007\n",
            "Epoch [9/10], Step[100/600], Loss:0.0004\n",
            "Epoch [9/10], Step[200/600], Loss:0.0009\n",
            "Epoch [9/10], Step[300/600], Loss:0.0246\n",
            "Epoch [9/10], Step[400/600], Loss:0.0006\n",
            "Epoch [9/10], Step[500/600], Loss:0.0012\n",
            "Epoch [9/10], Step[600/600], Loss:0.0002\n",
            "Epoch [10/10], Step[100/600], Loss:0.0002\n",
            "Epoch [10/10], Step[200/600], Loss:0.0001\n",
            "Epoch [10/10], Step[300/600], Loss:0.0007\n",
            "Epoch [10/10], Step[400/600], Loss:0.0012\n",
            "Epoch [10/10], Step[500/600], Loss:0.0002\n",
            "Epoch [10/10], Step[600/600], Loss:0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5CUkAokSdwq",
        "colab_type": "code",
        "colab": {},
        "outputId": "c7c7a3b0-306c-4a60-f129-37f044f46011"
      },
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = neuralNet_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.17 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtW3aet7Sdwr",
        "colab_type": "code",
        "colab": {},
        "outputId": "fa7bc28d-681a-4b61-d7cf-11b11cdce1a7"
      },
      "source": [
        "print(FcnNeuralNet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.FcnNeuralNet'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFZhj98gSdwt",
        "colab_type": "text"
      },
      "source": [
        "### Fully Connected MLP with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfxb6_tBTe_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "8fbfe5e7-c68a-45a9-ea77-f409d05319d9"
      },
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl (663.1MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 597kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2.0+cu92) (1.17.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.4.0+cu92) (0.46)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "  Found existing installation: torchvision 0.4.2\n",
            "    Uninstalling torchvision-0.4.2:\n",
            "      Successfully uninstalled torchvision-0.4.2\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLGWoJaSdwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS49BoleUXwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19ee5dd2-8d21-43cf-a2cb-baf5d0a0a497"
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpwQ_MFUdhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "375c3d62-0cab-426c-aad5-d53220eb5c6e"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUdXPR4STgGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67d78162-3d70-49c1-c280-070bf38ad300"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"% s will be used for training/testing\" % device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda will be used for training/testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poO9-LfKSdww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neural net input size\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFod3B2HSdwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = torchvision.datasets.MNIST(root='../data', train=True,\n",
        "                                   download=True, transform=transform)\n",
        "test_data = torchvision.datasets.MNIST(root='../data', train=False,\n",
        "                                  download=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqh_SmLjSdwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEi_eSm_Sdw1",
        "colab_type": "text"
      },
      "source": [
        "Visualize a batch of Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLGObdYaSdw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a84102ec-ccde-478d-f695-8b60dfbe0098"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# obtain one batch of training images\n",
        "batch_iter = iter(train_loader)\n",
        "images_batch, labels_batch = batch_iter.next()\n",
        "\n",
        "image = images_batch[0]\n",
        "\n",
        "img = np.array(image, dtype='float')\n",
        "img = img.reshape((28, 28))\n",
        "\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZqerDRapSdw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "7ba54535-3280-4b99-c437-874023d7f5e2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "batch_iter = iter(train_loader)\n",
        "images_batch, labels_batch = batch_iter.next()\n",
        "\n",
        "plt.figure(figsize=(25, 4))\n",
        "for idx, image in enumerate(images_batch):\n",
        "    img = np.array(image, dtype='float')\n",
        "    img = img.reshape((28, 28))\n",
        "    plt.subplot(2, 10, (idx + 1))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABYEAAAD7CAYAAAA8Tlu1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFRAH9g0Sdw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0a54642a-f8c6-4392-8fc6-61f4029d4398"
      },
      "source": [
        "# define the NN architecture\n",
        "class FcnNeuralNetDropOut(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # number of hidden nodes in each layer (512)\n",
        "        hidden_1 = 512\n",
        "        hidden_2 = 512\n",
        "        # linear layer (784 -> hidden_1)\n",
        "        self.fc1 = nn.Linear(28 * 28, hidden_1)\n",
        "        # linear layer (n_hidden -> hidden_2)\n",
        "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
        "        # linear layer (n_hidden -> 10)\n",
        "        self.fc3 = nn.Linear(hidden_2, 10)\n",
        "        # dropout prevents overfitting of data\n",
        "        # dropout layer (p=0.2)\n",
        "        self.dropout_02 = nn.Dropout(0.2)\n",
        "        # dropout layer (p=0.1)        \n",
        "        self.dropout_01 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout_02(x)\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout_01(x)\n",
        "        # add output layer\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "model = FcnNeuralNetDropOut()\n",
        "print(model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FcnNeuralNetDropOut(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (dropout_02): Dropout(p=0.2, inplace=False)\n",
            "  (dropout_01): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kldmSJzWSdw-",
        "colab_type": "text"
      },
      "source": [
        "__Specify Loss Function and Optimizer__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kmLyNikSdw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQSbq6aWSdxA",
        "colab_type": "text"
      },
      "source": [
        "__Train the Network__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhq0bpxDSdxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "e40b1bf3-cf15-40ff-9c4e-5e33a3c72a1f"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 50\n",
        "\n",
        "# initialize tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.to(device)\n",
        "    model.train() # prep model for training\n",
        "    \n",
        "    for data, target in train_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.to(device)\n",
        "    model.eval() # prep model for evaluation\n",
        "    for data, target in valid_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update running validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        valid_loss_min = valid_loss\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.114746 \tValidation Loss: 0.120256\n",
            "Validation loss decreased (inf --> 0.120256).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.088363 \tValidation Loss: 0.102350\n",
            "Validation loss decreased (0.120256 --> 0.102350).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.075051 \tValidation Loss: 0.082097\n",
            "Validation loss decreased (0.102350 --> 0.082097).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.062743 \tValidation Loss: 0.097377\n",
            "Epoch: 5 \tTraining Loss: 0.055259 \tValidation Loss: 0.095763\n",
            "Epoch: 6 \tTraining Loss: 0.049380 \tValidation Loss: 0.097606\n",
            "Epoch: 7 \tTraining Loss: 0.044086 \tValidation Loss: 0.094389\n",
            "Epoch: 8 \tTraining Loss: 0.045200 \tValidation Loss: 0.108816\n",
            "Epoch: 9 \tTraining Loss: 0.041165 \tValidation Loss: 0.133797\n",
            "Epoch: 10 \tTraining Loss: 0.040669 \tValidation Loss: 0.107350\n",
            "Epoch: 11 \tTraining Loss: 0.040243 \tValidation Loss: 0.102755\n",
            "Epoch: 12 \tTraining Loss: 0.037726 \tValidation Loss: 0.102602\n",
            "Epoch: 13 \tTraining Loss: 0.031507 \tValidation Loss: 0.116116\n",
            "Epoch: 14 \tTraining Loss: 0.038289 \tValidation Loss: 0.125344\n",
            "Epoch: 15 \tTraining Loss: 0.032569 \tValidation Loss: 0.120035\n",
            "Epoch: 16 \tTraining Loss: 0.031363 \tValidation Loss: 0.136923\n",
            "Epoch: 17 \tTraining Loss: 0.030982 \tValidation Loss: 0.127461\n",
            "Epoch: 18 \tTraining Loss: 0.032102 \tValidation Loss: 0.113170\n",
            "Epoch: 19 \tTraining Loss: 0.026444 \tValidation Loss: 0.145197\n",
            "Epoch: 20 \tTraining Loss: 0.034655 \tValidation Loss: 0.132939\n",
            "Epoch: 21 \tTraining Loss: 0.027878 \tValidation Loss: 0.134736\n",
            "Epoch: 22 \tTraining Loss: 0.029025 \tValidation Loss: 0.160073\n",
            "Epoch: 23 \tTraining Loss: 0.033527 \tValidation Loss: 0.144946\n",
            "Epoch: 24 \tTraining Loss: 0.026517 \tValidation Loss: 0.137853\n",
            "Epoch: 25 \tTraining Loss: 0.030400 \tValidation Loss: 0.175161\n",
            "Epoch: 26 \tTraining Loss: 0.029877 \tValidation Loss: 0.179475\n",
            "Epoch: 27 \tTraining Loss: 0.028566 \tValidation Loss: 0.173535\n",
            "Epoch: 28 \tTraining Loss: 0.028552 \tValidation Loss: 0.194987\n",
            "Epoch: 29 \tTraining Loss: 0.030468 \tValidation Loss: 0.171975\n",
            "Epoch: 30 \tTraining Loss: 0.028144 \tValidation Loss: 0.189536\n",
            "Epoch: 31 \tTraining Loss: 0.029601 \tValidation Loss: 0.207175\n",
            "Epoch: 32 \tTraining Loss: 0.028537 \tValidation Loss: 0.212599\n",
            "Epoch: 33 \tTraining Loss: 0.028696 \tValidation Loss: 0.218251\n",
            "Epoch: 34 \tTraining Loss: 0.030461 \tValidation Loss: 0.184699\n",
            "Epoch: 35 \tTraining Loss: 0.026973 \tValidation Loss: 0.199290\n",
            "Epoch: 36 \tTraining Loss: 0.029394 \tValidation Loss: 0.175655\n",
            "Epoch: 37 \tTraining Loss: 0.030732 \tValidation Loss: 0.197930\n",
            "Epoch: 38 \tTraining Loss: 0.026236 \tValidation Loss: 0.193600\n",
            "Epoch: 39 \tTraining Loss: 0.027128 \tValidation Loss: 0.203577\n",
            "Epoch: 40 \tTraining Loss: 0.033322 \tValidation Loss: 0.175638\n",
            "Epoch: 41 \tTraining Loss: 0.026286 \tValidation Loss: 0.214125\n",
            "Epoch: 42 \tTraining Loss: 0.026298 \tValidation Loss: 0.218597\n",
            "Epoch: 43 \tTraining Loss: 0.029500 \tValidation Loss: 0.223112\n",
            "Epoch: 44 \tTraining Loss: 0.032981 \tValidation Loss: 0.212010\n",
            "Epoch: 45 \tTraining Loss: 0.023330 \tValidation Loss: 0.219341\n",
            "Epoch: 46 \tTraining Loss: 0.030441 \tValidation Loss: 0.231995\n",
            "Epoch: 47 \tTraining Loss: 0.025183 \tValidation Loss: 0.233391\n",
            "Epoch: 48 \tTraining Loss: 0.029099 \tValidation Loss: 0.205547\n",
            "Epoch: 49 \tTraining Loss: 0.025759 \tValidation Loss: 0.253735\n",
            "Epoch: 50 \tTraining Loss: 0.030990 \tValidation Loss: 0.243220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2R1uEkOSdxC",
        "colab_type": "text"
      },
      "source": [
        "__Test the Model__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjYo_1pQSdxD",
        "colab_type": "text"
      },
      "source": [
        "Test setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtKAjn6SdxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_dropout(m):\n",
        "    if type(m) == nn.Dropout:\n",
        "        m.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfAwVcgwSdxF",
        "colab_type": "code",
        "colab": {},
        "outputId": "76568f57-1477-4f8a-fea2-12fc632239f2"
      },
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "# prep model for evaluation\n",
        "model.eval()\n",
        "# Apply dropout on testing\n",
        "model.apply(apply_dropout)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FcnNeuralNetDropOut(\n",
              "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (dropout_02): Dropout(p=0.2, inplace=False)\n",
              "  (dropout_04): Dropout(p=0.4, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdbj6yuvSdxG",
        "colab_type": "text"
      },
      "source": [
        "test loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHECZZXkSdxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data, target in test_loader:\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff3a65vJSdxI",
        "colab_type": "code",
        "colab": {},
        "outputId": "0520e3ed-3a93-4cdd-81b2-ec7415532ba2"
      },
      "source": [
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.133751\n",
            "\n",
            "Test Accuracy of     0: 98% (965/980)\n",
            "Test Accuracy of     1: 98% (1122/1135)\n",
            "Test Accuracy of     2: 96% (1000/1032)\n",
            "Test Accuracy of     3: 96% (976/1010)\n",
            "Test Accuracy of     4: 97% (954/982)\n",
            "Test Accuracy of     5: 97% (868/892)\n",
            "Test Accuracy of     6: 97% (937/958)\n",
            "Test Accuracy of     7: 97% (998/1028)\n",
            "Test Accuracy of     8: 93% (908/974)\n",
            "Test Accuracy of     9: 95% (964/1009)\n",
            "\n",
            "Test Accuracy (Overall): 96% (9692/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlr7aFSASdxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}